from typing import List, Dict, Optional
import requests
from utils import CONFIG, get_beijing_time, get_output_path
from utils.config import SMTP_CONFIGS
from utils.formatter import html_escape, clean_title
from utils.datetime import format_time_filename
from utils.statistics import matches_word_groups, format_rank_display
from pathlib import Path
from crawler.process import load_frequency_words
import re
import time
from .record import PushRecordManager

import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.header import Header
from email.utils import formataddr, formatdate, make_msgid


# === æŠ¥å‘Šç”Ÿæˆ ===
def prepare_report_data(
    stats: List[Dict],
    failed_ids: Optional[List] = None,
    new_titles: Optional[Dict] = None,
    id_to_name: Optional[Dict] = None,
    mode: str = "daily",
) -> Dict:
    """å‡†å¤‡æŠ¥å‘Šæ•°æ®"""
    processed_new_titles = []

    # åœ¨å¢é‡æ¨¡å¼ä¸‹éšè—æ–°å¢æ–°é—»åŒºåŸŸ
    hide_new_section = mode == "incremental"

    # åªæœ‰åœ¨ééšè—æ¨¡å¼ä¸‹æ‰å¤„ç†æ–°å¢æ–°é—»éƒ¨åˆ†
    if not hide_new_section:
        filtered_new_titles = {}
        if new_titles and id_to_name:
            word_groups, filter_words = load_frequency_words()
            for source_id, titles_data in new_titles.items():
                filtered_titles = {}
                for title, title_data in titles_data.items():
                    if matches_word_groups(title, word_groups, filter_words):
                        filtered_titles[title] = title_data
                if filtered_titles:
                    filtered_new_titles[source_id] = filtered_titles

        if filtered_new_titles and id_to_name:
            for source_id, titles_data in filtered_new_titles.items():
                source_name = id_to_name.get(source_id, source_id)
                source_titles = []

                for title, title_data in titles_data.items():
                    url = title_data.get("url", "")
                    mobile_url = title_data.get("mobileUrl", "")
                    ranks = title_data.get("ranks", [])

                    processed_title = {
                        "title": title,
                        "source_name": source_name,
                        "time_display": "",
                        "count": 1,
                        "ranks": ranks,
                        "rank_threshold": CONFIG["RANK_THRESHOLD"],
                        "url": url,
                        "mobile_url": mobile_url,
                        "is_new": True,
                    }
                    source_titles.append(processed_title)

                if source_titles:
                    processed_new_titles.append(
                        {
                            "source_id": source_id,
                            "source_name": source_name,
                            "titles": source_titles,
                        }
                    )

    processed_stats = []
    for stat in stats:
        if stat["count"] <= 0:
            continue

        processed_titles = []
        for title_data in stat["titles"]:
            processed_title = {
                "title": title_data["title"],
                "source_name": title_data["source_name"],
                "time_display": title_data["time_display"],
                "count": title_data["count"],
                "ranks": title_data["ranks"],
                "rank_threshold": title_data["rank_threshold"],
                "url": title_data.get("url", ""),
                "mobile_url": title_data.get("mobileUrl", ""),
                "is_new": title_data.get("is_new", False),
            }
            processed_titles.append(processed_title)

        processed_stats.append(
            {
                "word": stat["word"],
                "count": stat["count"],
                "percentage": stat.get("percentage", 0),
                "titles": processed_titles,
            }
        )

    return {
        "stats": processed_stats,
        "new_titles": processed_new_titles,
        "failed_ids": failed_ids or [],
        "total_new_count": sum(
            len(source["titles"]) for source in processed_new_titles
        ),
    }


def format_title_for_platform(
    platform: str, title_data: Dict, show_source: bool = True
) -> str:
    """ç»Ÿä¸€çš„æ ‡é¢˜æ ¼å¼åŒ–æ–¹æ³•"""
    rank_display = format_rank_display(
        title_data["ranks"], title_data["rank_threshold"], platform
    )

    link_url = title_data["mobile_url"] or title_data["url"]

    cleaned_title = clean_title(title_data["title"])

    if platform == "feishu":
        if link_url:
            formatted_title = f"[{cleaned_title}]({link_url})"
        else:
            formatted_title = cleaned_title

        title_prefix = "ğŸ†• " if title_data.get("is_new") else ""

        if show_source:
            result = f"<font color='grey'>[{title_data['source_name']}]</font> {title_prefix}{formatted_title}"
        else:
            result = f"{title_prefix}{formatted_title}"

        if rank_display:
            result += f" {rank_display}"
        if title_data["time_display"]:
            result += f" <font color='grey'>- {title_data['time_display']}</font>"
        if title_data["count"] > 1:
            result += f" <font color='green'>({title_data['count']}æ¬¡)</font>"

        return result

    elif platform == "dingtalk":
        if link_url:
            formatted_title = f"[{cleaned_title}]({link_url})"
        else:
            formatted_title = cleaned_title

        title_prefix = "ğŸ†• " if title_data.get("is_new") else ""

        if show_source:
            result = f"[{title_data['source_name']}] {title_prefix}{formatted_title}"
        else:
            result = f"{title_prefix}{formatted_title}"

        if rank_display:
            result += f" {rank_display}"
        if title_data["time_display"]:
            result += f" - {title_data['time_display']}"
        if title_data["count"] > 1:
            result += f" ({title_data['count']}æ¬¡)"

        return result

    elif platform == "wework":
        if link_url:
            formatted_title = f"[{cleaned_title}]({link_url})"
        else:
            formatted_title = cleaned_title

        title_prefix = "ğŸ†• " if title_data.get("is_new") else ""

        if show_source:
            result = f"[{title_data['source_name']}] {title_prefix}{formatted_title}"
        else:
            result = f"{title_prefix}{formatted_title}"

        if rank_display:
            result += f" {rank_display}"
        if title_data["time_display"]:
            result += f" - {title_data['time_display']}"
        if title_data["count"] > 1:
            result += f" ({title_data['count']}æ¬¡)"

        return result

    elif platform == "telegram":
        if link_url:
            formatted_title = f'<a href="{link_url}">{html_escape(cleaned_title)}</a>'
        else:
            formatted_title = cleaned_title

        title_prefix = "ğŸ†• " if title_data.get("is_new") else ""

        if show_source:
            result = f"[{title_data['source_name']}] {title_prefix}{formatted_title}"
        else:
            result = f"{title_prefix}{formatted_title}"

        if rank_display:
            result += f" {rank_display}"
        if title_data["time_display"]:
            result += f" <code>- {title_data['time_display']}</code>"
        if title_data["count"] > 1:
            result += f" <code>({title_data['count']}æ¬¡)</code>"

        return result

    elif platform == "ntfy":
        if link_url:
            formatted_title = f"[{cleaned_title}]({link_url})"
        else:
            formatted_title = cleaned_title

        title_prefix = "ğŸ†• " if title_data.get("is_new") else ""

        if show_source:
            result = f"[{title_data['source_name']}] {title_prefix}{formatted_title}"
        else:
            result = f"{title_prefix}{formatted_title}"

        if rank_display:
            result += f" {rank_display}"
        if title_data["time_display"]:
            result += f" `- {title_data['time_display']}`"
        if title_data["count"] > 1:
            result += f" `({title_data['count']}æ¬¡)`"

        return result

    elif platform == "html":
        rank_display = format_rank_display(
            title_data["ranks"], title_data["rank_threshold"], "html"
        )

        link_url = title_data["mobile_url"] or title_data["url"]

        escaped_title = html_escape(cleaned_title)
        escaped_source_name = html_escape(title_data["source_name"])

        if link_url:
            escaped_url = html_escape(link_url)
            formatted_title = f'[{escaped_source_name}] <a href="{escaped_url}" target="_blank" class="news-link">{escaped_title}</a>'
        else:
            formatted_title = (
                f'[{escaped_source_name}] <span class="no-link">{escaped_title}</span>'
            )

        if rank_display:
            formatted_title += f" {rank_display}"
        if title_data["time_display"]:
            escaped_time = html_escape(title_data["time_display"])
            formatted_title += f" <font color='grey'>- {escaped_time}</font>"
        if title_data["count"] > 1:
            formatted_title += f" <font color='green'>({title_data['count']}æ¬¡)</font>"

        if title_data.get("is_new"):
            formatted_title = f"<div class='new-title'>ğŸ†• {formatted_title}</div>"

        return formatted_title

    else:
        return cleaned_title


def generate_html_report(
    stats: List[Dict],
    total_titles: int,
    failed_ids: Optional[List] = None,
    new_titles: Optional[Dict] = None,
    id_to_name: Optional[Dict] = None,
    mode: str = "daily",
    is_daily_summary: bool = False,
    update_info: Optional[Dict] = None,
) -> str:
    """ç”ŸæˆHTMLæŠ¥å‘Š"""
    if is_daily_summary:
        if mode == "current":
            filename = "å½“å‰æ¦œå•æ±‡æ€».html"
        elif mode == "incremental":
            filename = "å½“æ—¥å¢é‡.html"
        elif mode == "llm_analysis":
            filename = "LLMåˆ†ææŠ¥å‘Š.html"
        else:
            filename = "å½“æ—¥æ±‡æ€».html"
    else:
        if mode == "llm_analysis":
            filename = "LLMåˆ†ææŠ¥å‘Š.html"
        else:
            filename = f"{format_time_filename()}.html"

    file_path = get_output_path("html", filename)

    report_data = prepare_report_data(stats, failed_ids, new_titles, id_to_name, mode)

    html_content = render_html_content(
        report_data, total_titles, is_daily_summary, mode, update_info
    )

    with open(file_path, "w", encoding="utf-8") as f:
        f.write(html_content)

    if is_daily_summary:
        root_file_path = Path("index.html")
        with open(root_file_path, "w", encoding="utf-8") as f:
            f.write(html_content)

    return file_path


def render_html_content(
    report_data: Dict,
    total_titles: int,
    is_daily_summary: bool = False,
    mode: str = "daily",
    update_info: Optional[Dict] = None,
) -> str:
    """æ¸²æŸ“HTMLå†…å®¹"""
    html = """
    <!DOCTYPE html>
    <html>
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>çƒ­ç‚¹æ–°é—»åˆ†æ</title>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.4.1/html2canvas.min.js" integrity="sha512-BNaRQnYJYiPSqHHDb58B0yaPfCu+Wgds8Gp/gU33kqBtgNS4tSPHuGibyoeqMV/TJlSKda6FXzoEyYGjTe+vXA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
        <style>
            * { box-sizing: border-box; }
            body {
                font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', system-ui, sans-serif;
                margin: 0;
                padding: 16px;
                background: #fafafa;
                color: #333;
                line-height: 1.5;
            }

            .container {
                max-width: 600px;
                margin: 0 auto;
                background: white;
                border-radius: 12px;
                overflow: hidden;
                box-shadow: 0 2px 16px rgba(0,0,0,0.06);
            }

            .header {
                background: linear-gradient(135deg, #4f46e5 0%, #7c3aed 100%);
                color: white;
                padding: 32px 24px;
                text-align: center;
                position: relative;
            }

            .save-buttons {
                position: absolute;
                top: 16px;
                right: 16px;
                display: flex;
                gap: 8px;
            }

            .save-btn {
                background: rgba(255, 255, 255, 0.2);
                border: 1px solid rgba(255, 255, 255, 0.3);
                color: white;
                padding: 8px 16px;
                border-radius: 6px;
                cursor: pointer;
                font-size: 13px;
                font-weight: 500;
                transition: all 0.2s ease;
                backdrop-filter: blur(10px);
                white-space: nowrap;
            }

            .save-btn:hover {
                background: rgba(255, 255, 255, 0.3);
                border-color: rgba(255, 255, 255, 0.5);
                transform: translateY(-1px);
            }

            .save-btn:active {
                transform: translateY(0);
            }

            .save-btn:disabled {
                opacity: 0.6;
                cursor: not-allowed;
            }

            .header-title {
                font-size: 22px;
                font-weight: 700;
                margin: 0 0 20px 0;
            }

            .header-info {
                display: grid;
                grid-template-columns: 1fr 1fr;
                gap: 16px;
                font-size: 14px;
                opacity: 0.95;
            }

            .info-item {
                text-align: center;
            }

            .info-label {
                display: block;
                font-size: 12px;
                opacity: 0.8;
                margin-bottom: 4px;
            }

            .info-value {
                font-weight: 600;
                font-size: 16px;
            }

            .content {
                padding: 24px;
            }

            .word-group {
                margin-bottom: 40px;
            }

            .word-group:first-child {
                margin-top: 0;
            }

            .word-header {
                display: flex;
                align-items: center;
                justify-content: space-between;
                margin-bottom: 20px;
                padding-bottom: 8px;
                border-bottom: 1px solid #f0f0f0;
            }

            .word-info {
                display: flex;
                align-items: center;
                gap: 12px;
            }

            .word-name {
                font-size: 17px;
                font-weight: 600;
                color: #1a1a1a;
            }

            .word-count {
                color: #666;
                font-size: 13px;
                font-weight: 500;
            }

            .word-count.hot { color: #dc2626; font-weight: 600; }
            .word-count.warm { color: #ea580c; font-weight: 600; }

            .word-index {
                color: #999;
                font-size: 12px;
            }

            .news-item {
                margin-bottom: 20px;
                padding: 16px 0;
                border-bottom: 1px solid #f5f5f5;
                position: relative;
                display: flex;
                gap: 12px;
                align-items: center;
            }

            .news-item:last-child {
                border-bottom: none;
            }

            .news-item.new::after {
                content: "NEW";
                position: absolute;
                top: 12px;
                right: 0;
                background: #fbbf24;
                color: #92400e;
                font-size: 9px;
                font-weight: 700;
                padding: 3px 6px;
                border-radius: 4px;
                letter-spacing: 0.5px;
            }

            .news-number {
                color: #999;
                font-size: 13px;
                font-weight: 600;
                min-width: 20px;
                text-align: center;
                flex-shrink: 0;
                background: #f8f9fa;
                border-radius: 50%;
                width: 24px;
                height: 24px;
                display: flex;
                align-items: center;
                justify-content: center;
                align-self: flex-start;
                margin-top: 8px;
            }

            .news-content {
                flex: 1;
                min-width: 0;
                padding-right: 40px;
            }

            .news-item.new .news-content {
                padding-right: 50px;
            }

            .news-header {
                display: flex;
                align-items: center;
                gap: 8px;
                margin-bottom: 8px;
                flex-wrap: wrap;
            }

            .source-name {
                color: #666;
                font-size: 12px;
                font-weight: 500;
            }

            .rank-num {
                color: #fff;
                background: #6b7280;
                font-size: 10px;
                font-weight: 700;
                padding: 2px 6px;
                border-radius: 10px;
                min-width: 18px;
                text-align: center;
            }

            .rank-num.top { background: #dc2626; }
            .rank-num.high { background: #ea580c; }

            .time-info {
                color: #999;
                font-size: 11px;
            }

            .count-info {
                color: #059669;
                font-size: 11px;
                font-weight: 500;
            }

            .news-title {
                font-size: 15px;
                line-height: 1.4;
                color: #1a1a1a;
                margin: 0;
            }

            .news-link {
                color: #2563eb;
                text-decoration: none;
            }

            .news-link:hover {
                text-decoration: underline;
            }

            .news-link:visited {
                color: #7c3aed;
            }

            .new-section {
                margin-top: 40px;
                padding-top: 24px;
                border-top: 2px solid #f0f0f0;
            }

            .new-section-title {
                color: #1a1a1a;
                font-size: 16px;
                font-weight: 600;
                margin: 0 0 20px 0;
            }

            .new-source-group {
                margin-bottom: 24px;
            }

            .new-source-title {
                color: #666;
                font-size: 13px;
                font-weight: 500;
                margin: 0 0 12px 0;
                padding-bottom: 6px;
                border-bottom: 1px solid #f5f5f5;
            }

            .new-item {
                display: flex;
                align-items: center;
                gap: 12px;
                padding: 8px 0;
                border-bottom: 1px solid #f9f9f9;
            }

            .new-item:last-child {
                border-bottom: none;
            }

            .new-item-number {
                color: #999;
                font-size: 12px;
                font-weight: 600;
                min-width: 18px;
                text-align: center;
                flex-shrink: 0;
                background: #f8f9fa;
                border-radius: 50%;
                width: 20px;
                height: 20px;
                display: flex;
                align-items: center;
                justify-content: center;
            }

            .new-item-rank {
                color: #fff;
                background: #6b7280;
                font-size: 10px;
                font-weight: 700;
                padding: 3px 6px;
                border-radius: 8px;
                min-width: 20px;
                text-align: center;
                flex-shrink: 0;
            }

            .new-item-rank.top { background: #dc2626; }
            .new-item-rank.high { background: #ea580c; }

            .new-item-content {
                flex: 1;
                min-width: 0;
            }

            .new-item-title {
                font-size: 14px;
                line-height: 1.4;
                color: #1a1a1a;
                margin: 0;
            }

            .error-section {
                background: #fef2f2;
                border: 1px solid #fecaca;
                border-radius: 8px;
                padding: 16px;
                margin-bottom: 24px;
            }

            .error-title {
                color: #dc2626;
                font-size: 14px;
                font-weight: 600;
                margin: 0 0 8px 0;
            }

            .error-list {
                list-style: none;
                padding: 0;
                margin: 0;
            }

            .error-item {
                color: #991b1b;
                font-size: 13px;
                padding: 2px 0;
                font-family: 'SF Mono', Consolas, monospace;
            }

            .footer {
                margin-top: 32px;
                padding: 20px 24px;
                background: #f8f9fa;
                border-top: 1px solid #e5e7eb;
                text-align: center;
            }

            .footer-content {
                font-size: 13px;
                color: #6b7280;
                line-height: 1.6;
            }

            .footer-link {
                color: #4f46e5;
                text-decoration: none;
                font-weight: 500;
                transition: color 0.2s ease;
            }

            .footer-link:hover {
                color: #7c3aed;
                text-decoration: underline;
            }

            .project-name {
                font-weight: 600;
                color: #374151;
            }

            @media (max-width: 480px) {
                body { padding: 12px; }
                .header { padding: 24px 20px; }
                .content { padding: 20px; }
                .footer { padding: 16px 20px; }
                .header-info { grid-template-columns: 1fr; gap: 12px; }
                .news-header { gap: 6px; }
                .news-content { padding-right: 45px; }
                .news-item { gap: 8px; }
                .new-item { gap: 8px; }
                .news-number { width: 20px; height: 20px; font-size: 12px; }
                .save-buttons {
                    position: static;
                    margin-bottom: 16px;
                    display: flex;
                    gap: 8px;
                    justify-content: center;
                    flex-direction: column;
                    width: 100%;
                }
                .save-btn {
                    width: 100%;
                }
            }
        </style>
    </head>
    <body>
        <div class="container">
            <div class="header">
                <div class="save-buttons">
                    <button class="save-btn" onclick="saveAsImage()">ä¿å­˜ä¸ºå›¾ç‰‡</button>
                    <button class="save-btn" onclick="saveAsMultipleImages()">åˆ†æ®µä¿å­˜</button>
                </div>
                <div class="header-title">çƒ­ç‚¹æ–°é—»åˆ†æ</div>
                <div class="header-info">
                    <div class="info-item">
                        <span class="info-label">æŠ¥å‘Šç±»å‹</span>
                        <span class="info-value">"""

    # å¤„ç†æŠ¥å‘Šç±»å‹æ˜¾ç¤º
    if is_daily_summary:
        if mode == "current":
            html += "å½“å‰æ¦œå•"
        elif mode == "incremental":
            html += "å¢é‡æ¨¡å¼"
        elif mode == "llm_analysis":
            html += "LLMåˆ†æ"
        else:
            html += "å½“æ—¥æ±‡æ€»"
    else:
        if mode == "llm_analysis":
            html += "LLMåˆ†æ"
        else:
            html += "å®æ—¶åˆ†æ"

    html += """</span>
                    </div>
                    <div class="info-item">
                        <span class="info-label">æ–°é—»æ€»æ•°</span>
                        <span class="info-value">"""

    html += f"{total_titles} æ¡"

    # è®¡ç®—ç­›é€‰åçš„çƒ­ç‚¹æ–°é—»æ•°é‡
    hot_news_count = sum(len(stat["titles"]) for stat in report_data["stats"])

    html += """</span>
                    </div>
                    <div class="info-item">
                        <span class="info-label">çƒ­ç‚¹æ–°é—»</span>
                        <span class="info-value">"""

    html += f"{hot_news_count} æ¡"

    html += """</span>
                    </div>
                    <div class="info-item">
                        <span class="info-label">ç”Ÿæˆæ—¶é—´</span>
                        <span class="info-value">"""

    now = get_beijing_time()
    html += now.strftime("%m-%d %H:%M")

    html += """</span>
                    </div>
                </div>
            </div>

            <div class="content">"""

    # å¤„ç†å¤±è´¥IDé”™è¯¯ä¿¡æ¯
    if report_data["failed_ids"]:
        html += """
                <div class="error-section">
                    <div class="error-title">âš ï¸ è¯·æ±‚å¤±è´¥çš„å¹³å°</div>
                    <ul class="error-list">"""
        for id_value in report_data["failed_ids"]:
            html += f'<li class="error-item">{html_escape(id_value)}</li>'
        html += """
                    </ul>
                </div>"""

    # å¤„ç†ä¸»è¦ç»Ÿè®¡æ•°æ®
    if report_data["stats"]:
        total_count = len(report_data["stats"])

        for i, stat in enumerate(report_data["stats"], 1):
            count = stat["count"]

            # ç¡®å®šçƒ­åº¦ç­‰çº§
            if count >= 10:
                count_class = "hot"
            elif count >= 5:
                count_class = "warm"
            else:
                count_class = ""

            escaped_word = html_escape(stat["word"])

            html += f"""
                <div class="word-group">
                    <div class="word-header">
                        <div class="word-info">
                            <div class="word-name">{escaped_word}</div>
                            <div class="word-count {count_class}">{count} æ¡</div>
                        </div>
                        <div class="word-index">{i}/{total_count}</div>
                    </div>"""

            # å¤„ç†æ¯ä¸ªè¯ç»„ä¸‹çš„æ–°é—»æ ‡é¢˜ï¼Œç»™æ¯æ¡æ–°é—»æ ‡ä¸Šåºå·
            for j, title_data in enumerate(stat["titles"], 1):
                is_new = title_data.get("is_new", False)
                new_class = "new" if is_new else ""

                html += f"""
                    <div class="news-item {new_class}">
                        <div class="news-number">{j}</div>
                        <div class="news-content">
                            <div class="news-header">
                                <span class="source-name">{html_escape(title_data["source_name"])}</span>"""

                # å¤„ç†æ’åæ˜¾ç¤º
                ranks = title_data.get("ranks", [])
                if ranks:
                    min_rank = min(ranks)
                    max_rank = max(ranks)
                    rank_threshold = title_data.get("rank_threshold", 10)

                    # ç¡®å®šæ’åç­‰çº§
                    if min_rank <= 3:
                        rank_class = "top"
                    elif min_rank <= rank_threshold:
                        rank_class = "high"
                    else:
                        rank_class = ""

                    if min_rank == max_rank:
                        rank_text = str(min_rank)
                    else:
                        rank_text = f"{min_rank}-{max_rank}"

                    html += f'<span class="rank-num {rank_class}">{rank_text}</span>'

                # å¤„ç†æ—¶é—´æ˜¾ç¤º
                time_display = title_data.get("time_display", "")
                if time_display:
                    # ç®€åŒ–æ—¶é—´æ˜¾ç¤ºæ ¼å¼ï¼Œå°†æ³¢æµªçº¿æ›¿æ¢ä¸º~
                    simplified_time = (
                        time_display.replace(" ~ ", "~")
                        .replace("[", "")
                        .replace("]", "")
                    )
                    html += (
                        f'<span class="time-info">{html_escape(simplified_time)}</span>'
                    )

                # å¤„ç†å‡ºç°æ¬¡æ•°
                count_info = title_data.get("count", 1)
                if count_info > 1:
                    html += f'<span class="count-info">{count_info}æ¬¡</span>'

                html += """
                            </div>
                            <div class="news-title">"""

                # å¤„ç†æ ‡é¢˜å’Œé“¾æ¥
                escaped_title = html_escape(title_data["title"])
                link_url = title_data.get("mobile_url") or title_data.get("url", "")

                if link_url:
                    escaped_url = html_escape(link_url)
                    html += f'<a href="{escaped_url}" target="_blank" class="news-link">{escaped_title}</a>'
                else:
                    html += escaped_title

                html += """
                            </div>
                        </div>
                    </div>"""

            html += """
                </div>"""

    # å¤„ç†æ–°å¢æ–°é—»åŒºåŸŸ
    if report_data["new_titles"]:
        html += f"""
                <div class="new-section">
                    <div class="new-section-title">æœ¬æ¬¡æ–°å¢çƒ­ç‚¹ (å…± {report_data["total_new_count"]} æ¡)</div>"""

        for source_data in report_data["new_titles"]:
            escaped_source = html_escape(source_data["source_name"])
            titles_count = len(source_data["titles"])

            html += f"""
                    <div class="new-source-group">
                        <div class="new-source-title">{escaped_source} Â· {titles_count}æ¡</div>"""

            # ä¸ºæ–°å¢æ–°é—»ä¹Ÿæ·»åŠ åºå·
            for idx, title_data in enumerate(source_data["titles"], 1):
                ranks = title_data.get("ranks", [])

                # å¤„ç†æ–°å¢æ–°é—»çš„æ’åæ˜¾ç¤º
                rank_class = ""
                if ranks:
                    min_rank = min(ranks)
                    if min_rank <= 3:
                        rank_class = "top"
                    elif min_rank <= title_data.get("rank_threshold", 10):
                        rank_class = "high"

                    if len(ranks) == 1:
                        rank_text = str(ranks[0])
                    else:
                        rank_text = f"{min(ranks)}-{max(ranks)}"
                else:
                    rank_text = "?"

                html += f"""
                        <div class="new-item">
                            <div class="new-item-number">{idx}</div>
                            <div class="new-item-rank {rank_class}">{rank_text}</div>
                            <div class="new-item-content">
                                <div class="new-item-title">"""

                # å¤„ç†æ–°å¢æ–°é—»çš„é“¾æ¥
                escaped_title = html_escape(title_data["title"])
                link_url = title_data.get("mobile_url") or title_data.get("url", "")

                if link_url:
                    escaped_url = html_escape(link_url)
                    html += f'<a href="{escaped_url}" target="_blank" class="news-link">{escaped_title}</a>'
                else:
                    html += escaped_title

                html += """
                                </div>
                            </div>
                        </div>"""

            html += """
                    </div>"""

        html += """
                </div>"""

    html += """
            </div>

            <div class="footer">
                <div class="footer-content">
                    ç”± <span class="project-name">TrendRadar</span> ç”Ÿæˆ Â·
                    <a href="https://github.com/sansan0/TrendRadar" target="_blank" class="footer-link">
                        GitHub å¼€æºé¡¹ç›®
                    </a>"""

    if update_info:
        html += f"""
                    <br>
                    <span style="color: #ea580c; font-weight: 500;">
                        å‘ç°æ–°ç‰ˆæœ¬ {update_info["remote_version"]}ï¼Œå½“å‰ç‰ˆæœ¬ {update_info["current_version"]}
                    </span>"""

    html += """
                </div>
            </div>
        </div>

        <script>
            async function saveAsImage() {
                const button = event.target;
                const originalText = button.textContent;

                try {
                    button.textContent = 'ç”Ÿæˆä¸­...';
                    button.disabled = true;
                    window.scrollTo(0, 0);

                    // ç­‰å¾…é¡µé¢ç¨³å®š
                    await new Promise(resolve => setTimeout(resolve, 200));

                    // æˆªå›¾å‰éšè—æŒ‰é’®
                    const buttons = document.querySelector('.save-buttons');
                    buttons.style.visibility = 'hidden';

                    // å†æ¬¡ç­‰å¾…ç¡®ä¿æŒ‰é’®å®Œå…¨éšè—
                    await new Promise(resolve => setTimeout(resolve, 100));

                    const container = document.querySelector('.container');

                    const canvas = await html2canvas(container, {
                        backgroundColor: '#ffffff',
                        scale: 1.5,
                        useCORS: true,
                        allowTaint: false,
                        imageTimeout: 10000,
                        removeContainer: false,
                        foreignObjectRendering: false,
                        logging: false,
                        width: container.offsetWidth,
                        height: container.offsetHeight,
                        x: 0,
                        y: 0,
                        scrollX: 0,
                        scrollY: 0,
                        windowWidth: window.innerWidth,
                        windowHeight: window.innerHeight
                    });

                    buttons.style.visibility = 'visible';

                    const link = document.createElement('a');
                    const now = new Date();
                    const filename = `TrendRadar_çƒ­ç‚¹æ–°é—»åˆ†æ_${now.getFullYear()}${String(now.getMonth() + 1).padStart(2, '0')}${String(now.getDate()).padStart(2, '0')}_${String(now.getHours()).padStart(2, '0')}${String(now.getMinutes()).padStart(2, '0')}.png`;

                    link.download = filename;
                    link.href = canvas.toDataURL('image/png', 1.0);

                    // è§¦å‘ä¸‹è½½
                    document.body.appendChild(link);
                    link.click();
                    document.body.removeChild(link);

                    button.textContent = 'ä¿å­˜æˆåŠŸ!';
                    setTimeout(() => {
                        button.textContent = originalText;
                        button.disabled = false;
                    }, 2000);

                } catch (error) {
                    const buttons = document.querySelector('.save-buttons');
                    buttons.style.visibility = 'visible';
                    button.textContent = 'ä¿å­˜å¤±è´¥';
                    setTimeout(() => {
                        button.textContent = originalText;
                        button.disabled = false;
                    }, 2000);
                }
            }

            async function saveAsMultipleImages() {
                const button = event.target;
                const originalText = button.textContent;
                const container = document.querySelector('.container');
                const scale = 1.5;
                const maxHeight = 5000 / scale;

                try {
                    button.textContent = 'åˆ†æä¸­...';
                    button.disabled = true;

                    // è·å–æ‰€æœ‰å¯èƒ½çš„åˆ†å‰²å…ƒç´ 
                    const newsItems = Array.from(container.querySelectorAll('.news-item'));
                    const wordGroups = Array.from(container.querySelectorAll('.word-group'));
                    const newSection = container.querySelector('.new-section');
                    const errorSection = container.querySelector('.error-section');
                    const header = container.querySelector('.header');
                    const footer = container.querySelector('.footer');

                    // è®¡ç®—å…ƒç´ ä½ç½®å’Œé«˜åº¦
                    const containerRect = container.getBoundingClientRect();
                    const elements = [];

                    // æ·»åŠ headerä½œä¸ºå¿…é¡»åŒ…å«çš„å…ƒç´ 
                    elements.push({
                        type: 'header',
                        element: header,
                        top: 0,
                        bottom: header.offsetHeight,
                        height: header.offsetHeight
                    });

                    // æ·»åŠ é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                    if (errorSection) {
                        const rect = errorSection.getBoundingClientRect();
                        elements.push({
                            type: 'error',
                            element: errorSection,
                            top: rect.top - containerRect.top,
                            bottom: rect.bottom - containerRect.top,
                            height: rect.height
                        });
                    }

                    // æŒ‰word-groupåˆ†ç»„å¤„ç†news-item
                    wordGroups.forEach(group => {
                        const groupRect = group.getBoundingClientRect();
                        const groupNewsItems = group.querySelectorAll('.news-item');

                        // æ·»åŠ word-groupçš„headeréƒ¨åˆ†
                        const wordHeader = group.querySelector('.word-header');
                        if (wordHeader) {
                            const headerRect = wordHeader.getBoundingClientRect();
                            elements.push({
                                type: 'word-header',
                                element: wordHeader,
                                parent: group,
                                top: groupRect.top - containerRect.top,
                                bottom: headerRect.bottom - containerRect.top,
                                height: headerRect.height
                            });
                        }

                        // æ·»åŠ æ¯ä¸ªnews-item
                        groupNewsItems.forEach(item => {
                            const rect = item.getBoundingClientRect();
                            elements.push({
                                type: 'news-item',
                                element: item,
                                parent: group,
                                top: rect.top - containerRect.top,
                                bottom: rect.bottom - containerRect.top,
                                height: rect.height
                            });
                        });
                    });

                    // æ·»åŠ æ–°å¢æ–°é—»éƒ¨åˆ†
                    if (newSection) {
                        const rect = newSection.getBoundingClientRect();
                        elements.push({
                            type: 'new-section',
                            element: newSection,
                            top: rect.top - containerRect.top,
                            bottom: rect.bottom - containerRect.top,
                            height: rect.height
                        });
                    }

                    // æ·»åŠ footer
                    const footerRect = footer.getBoundingClientRect();
                    elements.push({
                        type: 'footer',
                        element: footer,
                        top: footerRect.top - containerRect.top,
                        bottom: footerRect.bottom - containerRect.top,
                        height: footer.offsetHeight
                    });

                    // è®¡ç®—åˆ†å‰²ç‚¹
                    const segments = [];
                    let currentSegment = { start: 0, end: 0, height: 0, includeHeader: true };
                    let headerHeight = header.offsetHeight;
                    currentSegment.height = headerHeight;

                    for (let i = 1; i < elements.length; i++) {
                        const element = elements[i];
                        const potentialHeight = element.bottom - currentSegment.start;

                        // æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ›å»ºæ–°åˆ†æ®µ
                        if (potentialHeight > maxHeight && currentSegment.height > headerHeight) {
                            // åœ¨å‰ä¸€ä¸ªå…ƒç´ ç»“æŸå¤„åˆ†å‰²
                            currentSegment.end = elements[i - 1].bottom;
                            segments.push(currentSegment);

                            // å¼€å§‹æ–°åˆ†æ®µ
                            currentSegment = {
                                start: currentSegment.end,
                                end: 0,
                                height: element.bottom - currentSegment.end,
                                includeHeader: false
                            };
                        } else {
                            currentSegment.height = potentialHeight;
                            currentSegment.end = element.bottom;
                        }
                    }

                    // æ·»åŠ æœ€åä¸€ä¸ªåˆ†æ®µ
                    if (currentSegment.height > 0) {
                        currentSegment.end = container.offsetHeight;
                        segments.push(currentSegment);
                    }

                    button.textContent = `ç”Ÿæˆä¸­ (0/${segments.length})...`;

                    // éšè—ä¿å­˜æŒ‰é’®
                    const buttons = document.querySelector('.save-buttons');
                    buttons.style.visibility = 'hidden';

                    // ä¸ºæ¯ä¸ªåˆ†æ®µç”Ÿæˆå›¾ç‰‡
                    const images = [];
                    for (let i = 0; i < segments.length; i++) {
                        const segment = segments[i];
                        button.textContent = `ç”Ÿæˆä¸­ (${i + 1}/${segments.length})...`;

                        // åˆ›å»ºä¸´æ—¶å®¹å™¨ç”¨äºæˆªå›¾
                        const tempContainer = document.createElement('div');
                        tempContainer.style.cssText = `
                            position: absolute;
                            left: -9999px;
                            top: 0;
                            width: ${container.offsetWidth}px;
                            background: white;
                        `;
                        tempContainer.className = 'container';

                        // å…‹éš†å®¹å™¨å†…å®¹
                        const clonedContainer = container.cloneNode(true);

                        // ç§»é™¤å…‹éš†å†…å®¹ä¸­çš„ä¿å­˜æŒ‰é’®
                        const clonedButtons = clonedContainer.querySelector('.save-buttons');
                        if (clonedButtons) {
                            clonedButtons.style.display = 'none';
                        }

                        tempContainer.appendChild(clonedContainer);
                        document.body.appendChild(tempContainer);

                        // ç­‰å¾…DOMæ›´æ–°
                        await new Promise(resolve => setTimeout(resolve, 100));

                        // ä½¿ç”¨html2canvasæˆªå–ç‰¹å®šåŒºåŸŸ
                        const canvas = await html2canvas(clonedContainer, {
                            backgroundColor: '#ffffff',
                            scale: scale,
                            useCORS: true,
                            allowTaint: false,
                            imageTimeout: 10000,
                            logging: false,
                            width: container.offsetWidth,
                            height: segment.end - segment.start,
                            x: 0,
                            y: segment.start,
                            windowWidth: window.innerWidth,
                            windowHeight: window.innerHeight
                        });

                        images.push(canvas.toDataURL('image/png', 1.0));

                        // æ¸…ç†ä¸´æ—¶å®¹å™¨
                        document.body.removeChild(tempContainer);
                    }

                    // æ¢å¤æŒ‰é’®æ˜¾ç¤º
                    buttons.style.visibility = 'visible';

                    // ä¸‹è½½æ‰€æœ‰å›¾ç‰‡
                    const now = new Date();
                    const baseFilename = `TrendRadar_çƒ­ç‚¹æ–°é—»åˆ†æ_${now.getFullYear()}${String(now.getMonth() + 1).padStart(2, '0')}${String(now.getDate()).padStart(2, '0')}_${String(now.getHours()).padStart(2, '0')}${String(now.getMinutes()).padStart(2, '0')}`;

                    for (let i = 0; i < images.length; i++) {
                        const link = document.createElement('a');
                        link.download = `${baseFilename}_part${i + 1}.png`;
                        link.href = images[i];
                        document.body.appendChild(link);
                        link.click();
                        document.body.removeChild(link);

                        // å»¶è¿Ÿä¸€ä¸‹é¿å…æµè§ˆå™¨é˜»æ­¢å¤šä¸ªä¸‹è½½
                        await new Promise(resolve => setTimeout(resolve, 100));
                    }

                    button.textContent = `å·²ä¿å­˜ ${segments.length} å¼ å›¾ç‰‡!`;
                    setTimeout(() => {
                        button.textContent = originalText;
                        button.disabled = false;
                    }, 2000);

                } catch (error) {
                    console.error('åˆ†æ®µä¿å­˜å¤±è´¥:', error);
                    const buttons = document.querySelector('.save-buttons');
                    buttons.style.visibility = 'visible';
                    button.textContent = 'ä¿å­˜å¤±è´¥';
                    setTimeout(() => {
                        button.textContent = originalText;
                        button.disabled = false;
                    }, 2000);
                }
            }

            document.addEventListener('DOMContentLoaded', function() {
                window.scrollTo(0, 0);
            });
        </script>
    </body>
    </html>
    """

    return html


def render_feishu_content(
    report_data: Dict, update_info: Optional[Dict] = None, mode: str = "daily"
) -> str:
    """æ¸²æŸ“é£ä¹¦å†…å®¹"""
    text_content = ""

    if report_data["stats"]:
        text_content += f"ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**\n\n"

    total_count = len(report_data["stats"])

    for i, stat in enumerate(report_data["stats"]):
        word = stat["word"]
        count = stat["count"]

        sequence_display = f"<font color='grey'>[{i + 1}/{total_count}]</font>"

        if count >= 10:
            text_content += f"ğŸ”¥ {sequence_display} **{word}** : <font color='red'>{count}</font> æ¡\n\n"
        elif count >= 5:
            text_content += f"ğŸ“ˆ {sequence_display} **{word}** : <font color='orange'>{count}</font> æ¡\n\n"
        else:
            text_content += f"ğŸ“Œ {sequence_display} **{word}** : {count} æ¡\n\n"

        for j, title_data in enumerate(stat["titles"], 1):
            formatted_title = format_title_for_platform(
                "feishu", title_data, show_source=True
            )
            text_content += f"  {j}. {formatted_title}\n"

            if j < len(stat["titles"]):
                text_content += "\n"

        if i < len(report_data["stats"]) - 1:
            text_content += f"\n{CONFIG['FEISHU_MESSAGE_SEPARATOR']}\n\n"

    if not text_content:
        if mode == "incremental":
            mode_text = "å¢é‡æ¨¡å¼ä¸‹æš‚æ— æ–°å¢åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        elif mode == "current":
            mode_text = "å½“å‰æ¦œå•æ¨¡å¼ä¸‹æš‚æ— åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        else:
            mode_text = "æš‚æ— åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        text_content = f"ğŸ“­ {mode_text}\n\n"

    if report_data["new_titles"]:
        if text_content and "æš‚æ— åŒ¹é…" not in text_content:
            text_content += f"\n{CONFIG['FEISHU_MESSAGE_SEPARATOR']}\n\n"

        text_content += (
            f"ğŸ†• **æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»** (å…± {report_data['total_new_count']} æ¡)\n\n"
        )

        for source_data in report_data["new_titles"]:
            text_content += (
                f"**{source_data['source_name']}** ({len(source_data['titles'])} æ¡):\n"
            )

            for j, title_data in enumerate(source_data["titles"], 1):
                title_data_copy = title_data.copy()
                title_data_copy["is_new"] = False
                formatted_title = format_title_for_platform(
                    "feishu", title_data_copy, show_source=False
                )
                text_content += f"  {j}. {formatted_title}\n"

            text_content += "\n"

    if report_data["failed_ids"]:
        if text_content and "æš‚æ— åŒ¹é…" not in text_content:
            text_content += f"\n{CONFIG['FEISHU_MESSAGE_SEPARATOR']}\n\n"

        text_content += "âš ï¸ **æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š**\n\n"
        for i, id_value in enumerate(report_data["failed_ids"], 1):
            text_content += f"  â€¢ <font color='red'>{id_value}</font>\n"

    now = get_beijing_time()
    text_content += (
        f"\n\n<font color='grey'>æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}</font>"
    )

    if update_info:
        text_content += f"\n<font color='grey'>TrendRadar å‘ç°æ–°ç‰ˆæœ¬ {update_info['remote_version']}ï¼Œå½“å‰ {update_info['current_version']}</font>"

    return text_content


def render_dingtalk_content(
    report_data: Dict, update_info: Optional[Dict] = None, mode: str = "daily"
) -> str:
    """æ¸²æŸ“é’‰é’‰å†…å®¹"""
    text_content = ""

    total_titles = sum(
        len(stat["titles"]) for stat in report_data["stats"] if stat["count"] > 0
    )
    now = get_beijing_time()

    text_content += f"**æ€»æ–°é—»æ•°ï¼š** {total_titles}\n\n"
    text_content += f"**æ—¶é—´ï¼š** {now.strftime('%Y-%m-%d %H:%M:%S')}\n\n"
    text_content += f"**ç±»å‹ï¼š** çƒ­ç‚¹åˆ†ææŠ¥å‘Š\n\n"

    text_content += "---\n\n"

    if report_data["stats"]:
        text_content += f"ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**\n\n"

        total_count = len(report_data["stats"])

        for i, stat in enumerate(report_data["stats"]):
            word = stat["word"]
            count = stat["count"]

            sequence_display = f"[{i + 1}/{total_count}]"

            if count >= 10:
                text_content += f"ğŸ”¥ {sequence_display} **{word}** : **{count}** æ¡\n\n"
            elif count >= 5:
                text_content += f"ğŸ“ˆ {sequence_display} **{word}** : **{count}** æ¡\n\n"
            else:
                text_content += f"ğŸ“Œ {sequence_display} **{word}** : {count} æ¡\n\n"

            for j, title_data in enumerate(stat["titles"], 1):
                formatted_title = format_title_for_platform(
                    "dingtalk", title_data, show_source=True
                )
                text_content += f"  {j}. {formatted_title}\n"

                if j < len(stat["titles"]):
                    text_content += "\n"

            if i < len(report_data["stats"]) - 1:
                text_content += f"\n---\n\n"

    if not report_data["stats"]:
        if mode == "incremental":
            mode_text = "å¢é‡æ¨¡å¼ä¸‹æš‚æ— æ–°å¢åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        elif mode == "current":
            mode_text = "å½“å‰æ¦œå•æ¨¡å¼ä¸‹æš‚æ— åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        else:
            mode_text = "æš‚æ— åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        text_content += f"ğŸ“­ {mode_text}\n\n"

    if report_data["new_titles"]:
        if text_content and "æš‚æ— åŒ¹é…" not in text_content:
            text_content += f"\n---\n\n"

        text_content += (
            f"ğŸ†• **æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»** (å…± {report_data['total_new_count']} æ¡)\n\n"
        )

        for source_data in report_data["new_titles"]:
            text_content += f"**{source_data['source_name']}** ({len(source_data['titles'])} æ¡):\n\n"

            for j, title_data in enumerate(source_data["titles"], 1):
                title_data_copy = title_data.copy()
                title_data_copy["is_new"] = False
                formatted_title = format_title_for_platform(
                    "dingtalk", title_data_copy, show_source=False
                )
                text_content += f"  {j}. {formatted_title}\n"

            text_content += "\n"

    if report_data["failed_ids"]:
        if text_content and "æš‚æ— åŒ¹é…" not in text_content:
            text_content += f"\n---\n\n"

        text_content += "âš ï¸ **æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š**\n\n"
        for i, id_value in enumerate(report_data["failed_ids"], 1):
            text_content += f"  â€¢ **{id_value}**\n"

    text_content += f"\n\n> æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}"

    if update_info:
        text_content += f"\n> TrendRadar å‘ç°æ–°ç‰ˆæœ¬ **{update_info['remote_version']}**ï¼Œå½“å‰ **{update_info['current_version']}**"

    return text_content


def split_content_into_batches(
    report_data: Dict,
    format_type: str,
    update_info: Optional[Dict] = None,
    max_bytes: int = None,
    mode: str = "daily",
) -> List[str]:
    """åˆ†æ‰¹å¤„ç†æ¶ˆæ¯å†…å®¹ï¼Œç¡®ä¿è¯ç»„æ ‡é¢˜+è‡³å°‘ç¬¬ä¸€æ¡æ–°é—»çš„å®Œæ•´æ€§"""
    if max_bytes is None:
        if format_type == "dingtalk":
            max_bytes = CONFIG.get("DINGTALK_BATCH_SIZE", 20000)
        elif format_type == "feishu":
            max_bytes = CONFIG.get("FEISHU_BATCH_SIZE", 29000)
        elif format_type == "ntfy":
            max_bytes = 3800
        else:
            max_bytes = CONFIG.get("MESSAGE_BATCH_SIZE", 4000)

    batches = []

    total_titles = sum(
        len(stat["titles"]) for stat in report_data["stats"] if stat["count"] > 0
    )
    now = get_beijing_time()

    base_header = ""
    if format_type == "wework":
        base_header = f"**æ€»æ–°é—»æ•°ï¼š** {total_titles}\n\n\n\n"
    elif format_type == "telegram":
        base_header = f"æ€»æ–°é—»æ•°ï¼š {total_titles}\n\n"
    elif format_type == "ntfy":
        base_header = f"**æ€»æ–°é—»æ•°ï¼š** {total_titles}\n\n"
    elif format_type == "feishu":
        base_header = ""
    elif format_type == "dingtalk":
        base_header = f"**æ€»æ–°é—»æ•°ï¼š** {total_titles}\n\n"
        base_header += f"**æ—¶é—´ï¼š** {now.strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        base_header += f"**ç±»å‹ï¼š** çƒ­ç‚¹åˆ†ææŠ¥å‘Š\n\n"
        base_header += "---\n\n"

    base_footer = ""
    if format_type == "wework":
        base_footer = f"\n\n\n> æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}"
        if update_info:
            base_footer += f"\n> TrendRadar å‘ç°æ–°ç‰ˆæœ¬ **{update_info['remote_version']}**ï¼Œå½“å‰ **{update_info['current_version']}**"
    elif format_type == "telegram":
        base_footer = f"\n\næ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}"
        if update_info:
            base_footer += f"\nTrendRadar å‘ç°æ–°ç‰ˆæœ¬ {update_info['remote_version']}ï¼Œå½“å‰ {update_info['current_version']}"
    elif format_type == "ntfy":
        base_footer = f"\n\n> æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}"
        if update_info:
            base_footer += f"\n> TrendRadar å‘ç°æ–°ç‰ˆæœ¬ **{update_info['remote_version']}**ï¼Œå½“å‰ **{update_info['current_version']}**"
    elif format_type == "feishu":
        base_footer = f"\n\n<font color='grey'>æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}</font>"
        if update_info:
            base_footer += f"\n<font color='grey'>TrendRadar å‘ç°æ–°ç‰ˆæœ¬ {update_info['remote_version']}ï¼Œå½“å‰ {update_info['current_version']}</font>"
    elif format_type == "dingtalk":
        base_footer = f"\n\n> æ›´æ–°æ—¶é—´ï¼š{now.strftime('%Y-%m-%d %H:%M:%S')}"
        if update_info:
            base_footer += f"\n> TrendRadar å‘ç°æ–°ç‰ˆæœ¬ **{update_info['remote_version']}**ï¼Œå½“å‰ **{update_info['current_version']}**"

    stats_header = ""
    if report_data["stats"]:
        if format_type == "wework":
            stats_header = f"ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**\n\n"
        elif format_type == "telegram":
            stats_header = f"ğŸ“Š çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡\n\n"
        elif format_type == "ntfy":
            stats_header = f"ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**\n\n"
        elif format_type == "feishu":
            stats_header = f"ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**\n\n"
        elif format_type == "dingtalk":
            stats_header = f"ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**\n\n"

    current_batch = base_header
    current_batch_has_content = False

    if (
        not report_data["stats"]
        and not report_data["new_titles"]
        and not report_data["failed_ids"]
    ):
        if mode == "incremental":
            mode_text = "å¢é‡æ¨¡å¼ä¸‹æš‚æ— æ–°å¢åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        elif mode == "current":
            mode_text = "å½“å‰æ¦œå•æ¨¡å¼ä¸‹æš‚æ— åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        else:
            mode_text = "æš‚æ— åŒ¹é…çš„çƒ­ç‚¹è¯æ±‡"
        simple_content = f"ğŸ“­ {mode_text}\n\n"
        final_content = base_header + simple_content + base_footer
        batches.append(final_content)
        return batches

    # å¤„ç†çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡
    if report_data["stats"]:
        total_count = len(report_data["stats"])

        # æ·»åŠ ç»Ÿè®¡æ ‡é¢˜
        test_content = current_batch + stats_header
        if (
            len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
            < max_bytes
        ):
            current_batch = test_content
            current_batch_has_content = True
        else:
            if current_batch_has_content:
                batches.append(current_batch + base_footer)
            current_batch = base_header + stats_header
            current_batch_has_content = True

        # é€ä¸ªå¤„ç†è¯ç»„ï¼ˆç¡®ä¿è¯ç»„æ ‡é¢˜+ç¬¬ä¸€æ¡æ–°é—»çš„åŸå­æ€§ï¼‰
        for i, stat in enumerate(report_data["stats"]):
            word = stat["word"]
            count = stat["count"]
            sequence_display = f"[{i + 1}/{total_count}]"

            # æ„å»ºè¯ç»„æ ‡é¢˜
            word_header = ""
            if format_type == "wework":
                if count >= 10:
                    word_header = (
                        f"ğŸ”¥ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                elif count >= 5:
                    word_header = (
                        f"ğŸ“ˆ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                else:
                    word_header = f"ğŸ“Œ {sequence_display} **{word}** : {count} æ¡\n\n"
            elif format_type == "telegram":
                if count >= 10:
                    word_header = f"ğŸ”¥ {sequence_display} {word} : {count} æ¡\n\n"
                elif count >= 5:
                    word_header = f"ğŸ“ˆ {sequence_display} {word} : {count} æ¡\n\n"
                else:
                    word_header = f"ğŸ“Œ {sequence_display} {word} : {count} æ¡\n\n"
            elif format_type == "ntfy":
                if count >= 10:
                    word_header = (
                        f"ğŸ”¥ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                elif count >= 5:
                    word_header = (
                        f"ğŸ“ˆ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                else:
                    word_header = f"ğŸ“Œ {sequence_display} **{word}** : {count} æ¡\n\n"
            elif format_type == "feishu":
                if count >= 10:
                    word_header = f"ğŸ”¥ <font color='grey'>{sequence_display}</font> **{word}** : <font color='red'>{count}</font> æ¡\n\n"
                elif count >= 5:
                    word_header = f"ğŸ“ˆ <font color='grey'>{sequence_display}</font> **{word}** : <font color='orange'>{count}</font> æ¡\n\n"
                else:
                    word_header = f"ğŸ“Œ <font color='grey'>{sequence_display}</font> **{word}** : {count} æ¡\n\n"
            elif format_type == "dingtalk":
                if count >= 10:
                    word_header = (
                        f"ğŸ”¥ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                elif count >= 5:
                    word_header = (
                        f"ğŸ“ˆ {sequence_display} **{word}** : **{count}** æ¡\n\n"
                    )
                else:
                    word_header = f"ğŸ“Œ {sequence_display} **{word}** : {count} æ¡\n\n"

            # æ„å»ºç¬¬ä¸€æ¡æ–°é—»
            first_news_line = ""
            if stat["titles"]:
                first_title_data = stat["titles"][0]
                if format_type == "wework":
                    formatted_title = format_title_for_platform(
                        "wework", first_title_data, show_source=True
                    )
                elif format_type == "telegram":
                    formatted_title = format_title_for_platform(
                        "telegram", first_title_data, show_source=True
                    )
                elif format_type == "ntfy":
                    formatted_title = format_title_for_platform(
                        "ntfy", first_title_data, show_source=True
                    )
                elif format_type == "feishu":
                    formatted_title = format_title_for_platform(
                        "feishu", first_title_data, show_source=True
                    )
                elif format_type == "dingtalk":
                    formatted_title = format_title_for_platform(
                        "dingtalk", first_title_data, show_source=True
                    )
                else:
                    formatted_title = f"{first_title_data['title']}"

                first_news_line = f"  1. {formatted_title}\n"
                if len(stat["titles"]) > 1:
                    first_news_line += "\n"

            # åŸå­æ€§æ£€æŸ¥ï¼šè¯ç»„æ ‡é¢˜+ç¬¬ä¸€æ¡æ–°é—»å¿…é¡»ä¸€èµ·å¤„ç†
            word_with_first_news = word_header + first_news_line
            test_content = current_batch + word_with_first_news

            if (
                len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                >= max_bytes
            ):
                # å½“å‰æ‰¹æ¬¡å®¹çº³ä¸ä¸‹ï¼Œå¼€å¯æ–°æ‰¹æ¬¡
                if current_batch_has_content:
                    batches.append(current_batch + base_footer)
                current_batch = base_header + stats_header + word_with_first_news
                current_batch_has_content = True
                start_index = 1
            else:
                current_batch = test_content
                current_batch_has_content = True
                start_index = 1

            # å¤„ç†å‰©ä½™æ–°é—»æ¡ç›®
            for j in range(start_index, len(stat["titles"])):
                title_data = stat["titles"][j]
                if format_type == "wework":
                    formatted_title = format_title_for_platform(
                        "wework", title_data, show_source=True
                    )
                elif format_type == "telegram":
                    formatted_title = format_title_for_platform(
                        "telegram", title_data, show_source=True
                    )
                elif format_type == "ntfy":
                    formatted_title = format_title_for_platform(
                        "ntfy", title_data, show_source=True
                    )
                elif format_type == "feishu":
                    formatted_title = format_title_for_platform(
                        "feishu", title_data, show_source=True
                    )
                elif format_type == "dingtalk":
                    formatted_title = format_title_for_platform(
                        "dingtalk", title_data, show_source=True
                    )
                else:
                    formatted_title = f"{title_data['title']}"

                news_line = f"  {j + 1}. {formatted_title}\n"
                if j < len(stat["titles"]) - 1:
                    news_line += "\n"

                test_content = current_batch + news_line
                if (
                    len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                    >= max_bytes
                ):
                    if current_batch_has_content:
                        batches.append(current_batch + base_footer)
                    current_batch = base_header + stats_header + word_header + news_line
                    current_batch_has_content = True
                else:
                    current_batch = test_content
                    current_batch_has_content = True

            # è¯ç»„é—´åˆ†éš”ç¬¦
            if i < len(report_data["stats"]) - 1:
                separator = ""
                if format_type == "wework":
                    separator = f"\n\n\n\n"
                elif format_type == "telegram":
                    separator = f"\n\n"
                elif format_type == "ntfy":
                    separator = f"\n\n"
                elif format_type == "feishu":
                    separator = f"\n{CONFIG['FEISHU_MESSAGE_SEPARATOR']}\n\n"
                elif format_type == "dingtalk":
                    separator = f"\n---\n\n"

                test_content = current_batch + separator
                if (
                    len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                    < max_bytes
                ):
                    current_batch = test_content

    # å¤„ç†æ–°å¢æ–°é—»ï¼ˆåŒæ ·ç¡®ä¿æ¥æºæ ‡é¢˜+ç¬¬ä¸€æ¡æ–°é—»çš„åŸå­æ€§ï¼‰
    if report_data["new_titles"]:
        new_header = ""
        if format_type == "wework":
            new_header = f"\n\n\n\nğŸ†• **æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»** (å…± {report_data['total_new_count']} æ¡)\n\n"
        elif format_type == "telegram":
            new_header = (
                f"\n\nğŸ†• æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—» (å…± {report_data['total_new_count']} æ¡)\n\n"
            )
        elif format_type == "ntfy":
            new_header = f"\n\nğŸ†• **æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»** (å…± {report_data['total_new_count']} æ¡)\n\n"
        elif format_type == "feishu":
            new_header = f"\n{CONFIG['FEISHU_MESSAGE_SEPARATOR']}\n\nğŸ†• **æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»** (å…± {report_data['total_new_count']} æ¡)\n\n"
        elif format_type == "dingtalk":
            new_header = f"\n---\n\nğŸ†• **æœ¬æ¬¡æ–°å¢çƒ­ç‚¹æ–°é—»** (å…± {report_data['total_new_count']} æ¡)\n\n"

        test_content = current_batch + new_header
        if (
            len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
            >= max_bytes
        ):
            if current_batch_has_content:
                batches.append(current_batch + base_footer)
            current_batch = base_header + new_header
            current_batch_has_content = True
        else:
            current_batch = test_content
            current_batch_has_content = True

        # é€ä¸ªå¤„ç†æ–°å¢æ–°é—»æ¥æº
        for source_data in report_data["new_titles"]:
            source_header = ""
            if format_type == "wework":
                source_header = f"**{source_data['source_name']}** ({len(source_data['titles'])} æ¡):\n\n"
            elif format_type == "telegram":
                source_header = f"{source_data['source_name']} ({len(source_data['titles'])} æ¡):\n\n"
            elif format_type == "ntfy":
                source_header = f"**{source_data['source_name']}** ({len(source_data['titles'])} æ¡):\n\n"
            elif format_type == "feishu":
                source_header = f"**{source_data['source_name']}** ({len(source_data['titles'])} æ¡):\n\n"
            elif format_type == "dingtalk":
                source_header = f"**{source_data['source_name']}** ({len(source_data['titles'])} æ¡):\n\n"

            # æ„å»ºç¬¬ä¸€æ¡æ–°å¢æ–°é—»
            first_news_line = ""
            if source_data["titles"]:
                first_title_data = source_data["titles"][0]
                title_data_copy = first_title_data.copy()
                title_data_copy["is_new"] = False

                if format_type == "wework":
                    formatted_title = format_title_for_platform(
                        "wework", title_data_copy, show_source=False
                    )
                elif format_type == "telegram":
                    formatted_title = format_title_for_platform(
                        "telegram", title_data_copy, show_source=False
                    )
                elif format_type == "feishu":
                    formatted_title = format_title_for_platform(
                        "feishu", title_data_copy, show_source=False
                    )
                elif format_type == "dingtalk":
                    formatted_title = format_title_for_platform(
                        "dingtalk", title_data_copy, show_source=False
                    )
                else:
                    formatted_title = f"{title_data_copy['title']}"

                first_news_line = f"  1. {formatted_title}\n"

            # åŸå­æ€§æ£€æŸ¥ï¼šæ¥æºæ ‡é¢˜+ç¬¬ä¸€æ¡æ–°é—»
            source_with_first_news = source_header + first_news_line
            test_content = current_batch + source_with_first_news

            if (
                len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                >= max_bytes
            ):
                if current_batch_has_content:
                    batches.append(current_batch + base_footer)
                current_batch = base_header + new_header + source_with_first_news
                current_batch_has_content = True
                start_index = 1
            else:
                current_batch = test_content
                current_batch_has_content = True
                start_index = 1

            # å¤„ç†å‰©ä½™æ–°å¢æ–°é—»
            for j in range(start_index, len(source_data["titles"])):
                title_data = source_data["titles"][j]
                title_data_copy = title_data.copy()
                title_data_copy["is_new"] = False

                if format_type == "wework":
                    formatted_title = format_title_for_platform(
                        "wework", title_data_copy, show_source=False
                    )
                elif format_type == "telegram":
                    formatted_title = format_title_for_platform(
                        "telegram", title_data_copy, show_source=False
                    )
                elif format_type == "feishu":
                    formatted_title = format_title_for_platform(
                        "feishu", title_data_copy, show_source=False
                    )
                elif format_type == "dingtalk":
                    formatted_title = format_title_for_platform(
                        "dingtalk", title_data_copy, show_source=False
                    )
                else:
                    formatted_title = f"{title_data_copy['title']}"

                news_line = f"  {j + 1}. {formatted_title}\n"

                test_content = current_batch + news_line
                if (
                    len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                    >= max_bytes
                ):
                    if current_batch_has_content:
                        batches.append(current_batch + base_footer)
                    current_batch = base_header + new_header + source_header + news_line
                    current_batch_has_content = True
                else:
                    current_batch = test_content
                    current_batch_has_content = True

            current_batch += "\n"

    if report_data["failed_ids"]:
        failed_header = ""
        if format_type == "wework":
            failed_header = f"\n\n\n\nâš ï¸ **æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š**\n\n"
        elif format_type == "telegram":
            failed_header = f"\n\nâš ï¸ æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š\n\n"
        elif format_type == "ntfy":
            failed_header = f"\n\nâš ï¸ **æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š**\n\n"
        elif format_type == "feishu":
            failed_header = f"\n{CONFIG['FEISHU_MESSAGE_SEPARATOR']}\n\nâš ï¸ **æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š**\n\n"
        elif format_type == "dingtalk":
            failed_header = f"\n---\n\nâš ï¸ **æ•°æ®è·å–å¤±è´¥çš„å¹³å°ï¼š**\n\n"

        test_content = current_batch + failed_header
        if (
            len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
            >= max_bytes
        ):
            if current_batch_has_content:
                batches.append(current_batch + base_footer)
            current_batch = base_header + failed_header
            current_batch_has_content = True
        else:
            current_batch = test_content
            current_batch_has_content = True

        for i, id_value in enumerate(report_data["failed_ids"], 1):
            if format_type == "feishu":
                failed_line = f"  â€¢ <font color='red'>{id_value}</font>\n"
            elif format_type == "dingtalk":
                failed_line = f"  â€¢ **{id_value}**\n"
            else:
                failed_line = f"  â€¢ {id_value}\n"

            test_content = current_batch + failed_line
            if (
                len(test_content.encode("utf-8")) + len(base_footer.encode("utf-8"))
                >= max_bytes
            ):
                if current_batch_has_content:
                    batches.append(current_batch + base_footer)
                current_batch = base_header + failed_header + failed_line
                current_batch_has_content = True
            else:
                current_batch = test_content
                current_batch_has_content = True

    # å®Œæˆæœ€åæ‰¹æ¬¡
    if current_batch_has_content:
        batches.append(current_batch + base_footer)

    return batches


def send_to_notifications(
    stats: List[Dict],
    failed_ids: Optional[List] = None,
    report_type: str = "å½“æ—¥æ±‡æ€»",
    new_titles: Optional[Dict] = None,
    id_to_name: Optional[Dict] = None,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
    html_file_path: Optional[str] = None,
) -> Dict[str, bool]:
    """å‘é€æ•°æ®åˆ°å¤šä¸ªé€šçŸ¥å¹³å°"""
    results = {}

    if CONFIG["PUSH_WINDOW"]["ENABLED"]:
        push_manager = PushRecordManager()
        time_range_start = CONFIG["PUSH_WINDOW"]["TIME_RANGE"]["START"]
        time_range_end = CONFIG["PUSH_WINDOW"]["TIME_RANGE"]["END"]

        if not push_manager.is_in_time_range(time_range_start, time_range_end):
            now = get_beijing_time()
            print(
                f"æ¨é€çª—å£æ§åˆ¶ï¼šå½“å‰æ—¶é—´ {now.strftime('%H:%M')} ä¸åœ¨æ¨é€æ—¶é—´çª—å£ {time_range_start}-{time_range_end} å†…ï¼Œè·³è¿‡æ¨é€"
            )
            return results

        if CONFIG["PUSH_WINDOW"]["ONCE_PER_DAY"]:
            if push_manager.has_pushed_today():
                print(f"æ¨é€çª—å£æ§åˆ¶ï¼šä»Šå¤©å·²æ¨é€è¿‡ï¼Œè·³è¿‡æœ¬æ¬¡æ¨é€")
                return results
            else:
                print(f"æ¨é€çª—å£æ§åˆ¶ï¼šä»Šå¤©é¦–æ¬¡æ¨é€")

    report_data = prepare_report_data(stats, failed_ids, new_titles, id_to_name, mode)

    feishu_url = CONFIG["FEISHU_WEBHOOK_URL"]
    dingtalk_url = CONFIG["DINGTALK_WEBHOOK_URL"]
    wework_url = CONFIG["WEWORK_WEBHOOK_URL"]
    telegram_token = CONFIG["TELEGRAM_BOT_TOKEN"]
    telegram_chat_id = CONFIG["TELEGRAM_CHAT_ID"]
    email_from = CONFIG["EMAIL_FROM"]
    email_password = CONFIG["EMAIL_PASSWORD"]
    email_to = CONFIG["EMAIL_TO"]
    email_smtp_server = CONFIG.get("EMAIL_SMTP_SERVER", "")
    email_smtp_port = CONFIG.get("EMAIL_SMTP_PORT", "")
    ntfy_server_url = CONFIG["NTFY_SERVER_URL"]
    ntfy_topic = CONFIG["NTFY_TOPIC"]
    ntfy_token = CONFIG.get("NTFY_TOKEN", "")
    bark_url = CONFIG["BARK_URL"]

    update_info_to_send = update_info if CONFIG["SHOW_VERSION_UPDATE"] else None

    # å‘é€åˆ°é£ä¹¦
    if feishu_url:
        results["feishu"] = send_to_feishu(
            feishu_url, report_data, report_type, update_info_to_send, proxy_url, mode
        )

    # å‘é€åˆ°é’‰é’‰
    if dingtalk_url:
        results["dingtalk"] = send_to_dingtalk(
            dingtalk_url, report_data, report_type, update_info_to_send, proxy_url, mode
        )

    # å‘é€åˆ°ä¼ä¸šå¾®ä¿¡
    if wework_url:
        results["wework"] = send_to_wework(
            wework_url, report_data, report_type, update_info_to_send, proxy_url, mode
        )

    # å‘é€åˆ° Telegram
    if telegram_token and telegram_chat_id:
        results["telegram"] = send_to_telegram(
            telegram_token,
            telegram_chat_id,
            report_data,
            report_type,
            update_info_to_send,
            proxy_url,
            mode,
        )

    # å‘é€åˆ° ntfy
    if ntfy_server_url and ntfy_topic:
        results["ntfy"] = send_to_ntfy(
            ntfy_server_url,
            ntfy_topic,
            ntfy_token,
            report_data,
            report_type,
            update_info_to_send,
            proxy_url,
            mode,
        )

    # å‘é€åˆ° Bark
    if bark_url:
        results["bark"] = send_to_bark(
            bark_url,
            report_data,
            report_type,
            update_info_to_send,
            proxy_url,
            mode,
        )

    # å‘é€é‚®ä»¶
    if email_from and email_password and email_to:
        results["email"] = send_to_email(
            email_from,
            email_password,
            email_to,
            report_type,
            html_file_path,
            email_smtp_server,
            email_smtp_port,
        )

    if not results:
        print("æœªé…ç½®ä»»ä½•é€šçŸ¥æ¸ é“ï¼Œè·³è¿‡é€šçŸ¥å‘é€")

    # å¦‚æœæˆåŠŸå‘é€äº†ä»»ä½•é€šçŸ¥ï¼Œä¸”å¯ç”¨äº†æ¯å¤©åªæ¨ä¸€æ¬¡ï¼Œåˆ™è®°å½•æ¨é€
    if (
        CONFIG["PUSH_WINDOW"]["ENABLED"]
        and CONFIG["PUSH_WINDOW"]["ONCE_PER_DAY"]
        and any(results.values())
    ):
        push_manager = PushRecordManager()
        push_manager.record_push(report_type)

    return results


def send_to_feishu(
    webhook_url: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
) -> bool:
    """å‘é€åˆ°é£ä¹¦ï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼‰"""
    headers = {"Content-Type": "application/json"}
    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # è·å–åˆ†æ‰¹å†…å®¹ï¼Œä½¿ç”¨é£ä¹¦ä¸“ç”¨çš„æ‰¹æ¬¡å¤§å°
    batches = split_content_into_batches(
        report_data,
        "feishu",
        update_info,
        max_bytes=CONFIG.get("FEISHU_BATCH_SIZE", 29000),
        mode=mode,
    )

    print(f"é£ä¹¦æ¶ˆæ¯åˆ†ä¸º {len(batches)} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # é€æ‰¹å‘é€
    for i, batch_content in enumerate(batches, 1):
        batch_size = len(batch_content.encode("utf-8"))
        print(
            f"å‘é€é£ä¹¦ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡ï¼Œå¤§å°ï¼š{batch_size} å­—èŠ‚ [{report_type}]"
        )

        # æ·»åŠ æ‰¹æ¬¡æ ‡è¯†
        if len(batches) > 1:
            batch_header = f"**[ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡]**\n\n"
            # å°†æ‰¹æ¬¡æ ‡è¯†æ’å…¥åˆ°é€‚å½“ä½ç½®ï¼ˆåœ¨ç»Ÿè®¡æ ‡é¢˜ä¹‹åï¼‰
            if "ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**" in batch_content:
                batch_content = batch_content.replace(
                    "ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**\n\n", f"ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡** {batch_header}"
                )
            else:
                # å¦‚æœæ²¡æœ‰ç»Ÿè®¡æ ‡é¢˜ï¼Œç›´æ¥åœ¨å¼€å¤´æ·»åŠ 
                batch_content = batch_header + batch_content

        total_titles = sum(
            len(stat["titles"]) for stat in report_data["stats"] if stat["count"] > 0
        )
        now = get_beijing_time()

        payload = {
            "msg_type": "text",
            "content": {
                "total_titles": total_titles,
                "timestamp": now.strftime("%Y-%m-%d %H:%M:%S"),
                "report_type": report_type,
                "text": batch_content,
            },
        }

        try:
            response = requests.post(
                webhook_url, headers=headers, json=payload, proxies=proxies, timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                # æ£€æŸ¥é£ä¹¦çš„å“åº”çŠ¶æ€
                if result.get("StatusCode") == 0 or result.get("code") == 0:
                    print(f"é£ä¹¦ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                    # æ‰¹æ¬¡é—´é—´éš”
                    if i < len(batches):
                        time.sleep(CONFIG["BATCH_SEND_INTERVAL"])
                else:
                    error_msg = result.get("msg") or result.get(
                        "StatusMessage", "æœªçŸ¥é”™è¯¯"
                    )
                    print(
                        f"é£ä¹¦ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{error_msg}"
                    )
                    return False
            else:
                print(
                    f"é£ä¹¦ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                return False
        except Exception as e:
            print(f"é£ä¹¦ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
            return False

    print(f"é£ä¹¦æ‰€æœ‰ {len(batches)} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
    return True


def send_to_dingtalk(
    webhook_url: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
) -> bool:
    """å‘é€åˆ°é’‰é’‰ï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼‰"""
    headers = {"Content-Type": "application/json"}
    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # è·å–åˆ†æ‰¹å†…å®¹ï¼Œä½¿ç”¨é’‰é’‰ä¸“ç”¨çš„æ‰¹æ¬¡å¤§å°
    batches = split_content_into_batches(
        report_data,
        "dingtalk",
        update_info,
        max_bytes=CONFIG.get("DINGTALK_BATCH_SIZE", 20000),
        mode=mode,
    )

    print(f"é’‰é’‰æ¶ˆæ¯åˆ†ä¸º {len(batches)} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # é€æ‰¹å‘é€
    for i, batch_content in enumerate(batches, 1):
        batch_size = len(batch_content.encode("utf-8"))
        print(
            f"å‘é€é’‰é’‰ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡ï¼Œå¤§å°ï¼š{batch_size} å­—èŠ‚ [{report_type}]"
        )

        # æ·»åŠ æ‰¹æ¬¡æ ‡è¯†
        if len(batches) > 1:
            batch_header = f"**[ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡]**\n\n"
            # å°†æ‰¹æ¬¡æ ‡è¯†æ’å…¥åˆ°é€‚å½“ä½ç½®ï¼ˆåœ¨æ ‡é¢˜ä¹‹åï¼‰
            if "ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**" in batch_content:
                batch_content = batch_content.replace(
                    "ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡**\n\n", f"ğŸ“Š **çƒ­ç‚¹è¯æ±‡ç»Ÿè®¡** {batch_header}\n\n"
                )
            else:
                # å¦‚æœæ²¡æœ‰ç»Ÿè®¡æ ‡é¢˜ï¼Œç›´æ¥åœ¨å¼€å¤´æ·»åŠ 
                batch_content = batch_header + batch_content

        payload = {
            "msgtype": "markdown",
            "markdown": {
                "title": f"TrendRadar çƒ­ç‚¹åˆ†ææŠ¥å‘Š - {report_type}",
                "text": batch_content,
            },
        }

        try:
            response = requests.post(
                webhook_url, headers=headers, json=payload, proxies=proxies, timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                if result.get("errcode") == 0:
                    print(f"é’‰é’‰ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                    # æ‰¹æ¬¡é—´é—´éš”
                    if i < len(batches):
                        time.sleep(CONFIG["BATCH_SEND_INTERVAL"])
                else:
                    print(
                        f"é’‰é’‰ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{result.get('errmsg')}"
                    )
                    return False
            else:
                print(
                    f"é’‰é’‰ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                return False
        except Exception as e:
            print(f"é’‰é’‰ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
            return False

    print(f"é’‰é’‰æ‰€æœ‰ {len(batches)} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
    return True


def strip_markdown(text: str) -> str:
    """å»é™¤æ–‡æœ¬ä¸­çš„ markdown è¯­æ³•æ ¼å¼ï¼Œç”¨äºä¸ªäººå¾®ä¿¡æ¨é€"""

    # å»é™¤ç²—ä½“ **text** æˆ– __text__
    text = re.sub(r"\*\*(.+?)\*\*", r"\1", text)
    text = re.sub(r"__(.+?)__", r"\1", text)

    # å»é™¤æ–œä½“ *text* æˆ– _text_
    text = re.sub(r"\*(.+?)\*", r"\1", text)
    text = re.sub(r"_(.+?)_", r"\1", text)

    # å»é™¤åˆ é™¤çº¿ ~~text~~
    text = re.sub(r"~~(.+?)~~", r"\1", text)

    # è½¬æ¢é“¾æ¥ [text](url) -> text urlï¼ˆä¿ç•™ URLï¼‰
    text = re.sub(r"\[([^\]]+)\]\(([^)]+)\)", r"\1 \2", text)
    # å¦‚æœä¸éœ€è¦ä¿ç•™ URLï¼Œå¯ä»¥ä½¿ç”¨ä¸‹é¢è¿™è¡Œï¼ˆåªä¿ç•™æ ‡é¢˜æ–‡æœ¬ï¼‰ï¼š
    # text = re.sub(r'\[([^\]]+)\]\([^)]+\)', r'\1', text)

    # å»é™¤å›¾ç‰‡ ![alt](url) -> alt
    text = re.sub(r"!\[(.+?)\]\(.+?\)", r"\1", text)

    # å»é™¤è¡Œå†…ä»£ç  `code`
    text = re.sub(r"`(.+?)`", r"\1", text)

    # å»é™¤å¼•ç”¨ç¬¦å· >
    text = re.sub(r"^>\s*", "", text, flags=re.MULTILINE)

    # å»é™¤æ ‡é¢˜ç¬¦å· # ## ### ç­‰
    text = re.sub(r"^#+\s*", "", text, flags=re.MULTILINE)

    # å»é™¤æ°´å¹³åˆ†å‰²çº¿ --- æˆ– ***
    text = re.sub(r"^[\-\*]{3,}\s*$", "", text, flags=re.MULTILINE)

    # å»é™¤ HTML æ ‡ç­¾ <font color='xxx'>text</font> -> text
    text = re.sub(r"<font[^>]*>(.+?)</font>", r"\1", text)
    text = re.sub(r"<[^>]+>", "", text)

    # æ¸…ç†å¤šä½™çš„ç©ºè¡Œï¼ˆä¿ç•™æœ€å¤šä¸¤ä¸ªè¿ç»­ç©ºè¡Œï¼‰
    text = re.sub(r"\n{3,}", "\n\n", text)

    return text.strip()


def send_to_wework(
    webhook_url: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
) -> bool:
    """å‘é€åˆ°ä¼ä¸šå¾®ä¿¡ï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼Œæ”¯æŒ markdown å’Œ text ä¸¤ç§æ ¼å¼ï¼‰"""
    headers = {"Content-Type": "application/json"}
    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # è·å–æ¶ˆæ¯ç±»å‹é…ç½®ï¼ˆmarkdown æˆ– textï¼‰
    msg_type = CONFIG.get("WEWORK_MSG_TYPE", "markdown").lower()
    is_text_mode = msg_type == "text"

    if is_text_mode:
        print(f"ä¼ä¸šå¾®ä¿¡ä½¿ç”¨ text æ ¼å¼ï¼ˆä¸ªäººå¾®ä¿¡æ¨¡å¼ï¼‰[{report_type}]")
    else:
        print(f"ä¼ä¸šå¾®ä¿¡ä½¿ç”¨ markdown æ ¼å¼ï¼ˆç¾¤æœºå™¨äººæ¨¡å¼ï¼‰[{report_type}]")

    # è·å–åˆ†æ‰¹å†…å®¹
    batches = split_content_into_batches(report_data, "wework", update_info, mode=mode)

    print(f"ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯åˆ†ä¸º {len(batches)} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # é€æ‰¹å‘é€
    for i, batch_content in enumerate(batches, 1):
        # æ·»åŠ æ‰¹æ¬¡æ ‡è¯†
        if len(batches) > 1:
            if is_text_mode:
                batch_header = f"[ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡]\n\n"
            else:
                batch_header = f"**[ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡]**\n\n"
            batch_content = batch_header + batch_content

        # æ ¹æ®æ¶ˆæ¯ç±»å‹æ„å»º payload
        if is_text_mode:
            # text æ ¼å¼ï¼šå»é™¤ markdown è¯­æ³•
            plain_content = strip_markdown(batch_content)
            payload = {"msgtype": "text", "text": {"content": plain_content}}
            batch_size = len(plain_content.encode("utf-8"))
        else:
            # markdown æ ¼å¼ï¼šä¿æŒåŸæ ·
            payload = {"msgtype": "markdown", "markdown": {"content": batch_content}}
            batch_size = len(batch_content.encode("utf-8"))

        print(
            f"å‘é€ä¼ä¸šå¾®ä¿¡ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡ï¼Œå¤§å°ï¼š{batch_size} å­—èŠ‚ [{report_type}]"
        )

        try:
            response = requests.post(
                webhook_url, headers=headers, json=payload, proxies=proxies, timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                if result.get("errcode") == 0:
                    print(f"ä¼ä¸šå¾®ä¿¡ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                    # æ‰¹æ¬¡é—´é—´éš”
                    if i < len(batches):
                        time.sleep(CONFIG["BATCH_SEND_INTERVAL"])
                else:
                    print(
                        f"ä¼ä¸šå¾®ä¿¡ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{result.get('errmsg')}"
                    )
                    return False
            else:
                print(
                    f"ä¼ä¸šå¾®ä¿¡ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                return False
        except Exception as e:
            print(f"ä¼ä¸šå¾®ä¿¡ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
            return False

    print(f"ä¼ä¸šå¾®ä¿¡æ‰€æœ‰ {len(batches)} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
    return True


def send_to_telegram(
    bot_token: str,
    chat_id: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
) -> bool:
    """å‘é€åˆ°Telegramï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼‰"""
    headers = {"Content-Type": "application/json"}
    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"

    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # è·å–åˆ†æ‰¹å†…å®¹
    batches = split_content_into_batches(
        report_data, "telegram", update_info, mode=mode
    )

    print(f"Telegramæ¶ˆæ¯åˆ†ä¸º {len(batches)} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # é€æ‰¹å‘é€
    for i, batch_content in enumerate(batches, 1):
        batch_size = len(batch_content.encode("utf-8"))
        print(
            f"å‘é€Telegramç¬¬ {i}/{len(batches)} æ‰¹æ¬¡ï¼Œå¤§å°ï¼š{batch_size} å­—èŠ‚ [{report_type}]"
        )

        # æ·»åŠ æ‰¹æ¬¡æ ‡è¯†
        if len(batches) > 1:
            batch_header = f"<b>[ç¬¬ {i}/{len(batches)} æ‰¹æ¬¡]</b>\n\n"
            batch_content = batch_header + batch_content

        payload = {
            "chat_id": chat_id,
            "text": batch_content,
            "parse_mode": "HTML",
            "disable_web_page_preview": True,
        }

        try:
            response = requests.post(
                url, headers=headers, json=payload, proxies=proxies, timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                if result.get("ok"):
                    print(f"Telegramç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]")
                    # æ‰¹æ¬¡é—´é—´éš”
                    if i < len(batches):
                        time.sleep(CONFIG["BATCH_SEND_INTERVAL"])
                else:
                    print(
                        f"Telegramç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{result.get('description')}"
                    )
                    return False
            else:
                print(
                    f"Telegramç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                return False
        except Exception as e:
            print(f"Telegramç¬¬ {i}/{len(batches)} æ‰¹æ¬¡å‘é€å‡ºé”™ [{report_type}]ï¼š{e}")
            return False

    print(f"Telegramæ‰€æœ‰ {len(batches)} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
    return True


def send_to_email(
    from_email: str,
    password: str,
    to_email: str,
    report_type: str,
    html_file_path: str,
    custom_smtp_server: Optional[str] = None,
    custom_smtp_port: Optional[int] = None,
) -> bool:
    """å‘é€é‚®ä»¶é€šçŸ¥"""
    try:
        if not html_file_path or not Path(html_file_path).exists():
            print(f"é”™è¯¯ï¼šHTMLæ–‡ä»¶ä¸å­˜åœ¨æˆ–æœªæä¾›: {html_file_path}")
            return False

        print(f"ä½¿ç”¨HTMLæ–‡ä»¶: {html_file_path}")
        with open(html_file_path, "r", encoding="utf-8") as f:
            html_content = f.read()

        domain = from_email.split("@")[-1].lower()

        if custom_smtp_server and custom_smtp_port:
            # ä½¿ç”¨è‡ªå®šä¹‰ SMTP é…ç½®
            smtp_server = custom_smtp_server
            smtp_port = int(custom_smtp_port)
            # æ ¹æ®ç«¯å£åˆ¤æ–­åŠ å¯†æ–¹å¼ï¼š465=SSL, 587=TLS
            if smtp_port == 465:
                use_tls = False  # SSL æ¨¡å¼ï¼ˆSMTP_SSLï¼‰
            elif smtp_port == 587:
                use_tls = True  # TLS æ¨¡å¼ï¼ˆSTARTTLSï¼‰
            else:
                # å…¶ä»–ç«¯å£ä¼˜å…ˆå°è¯• TLSï¼ˆæ›´å®‰å…¨ï¼Œæ›´å¹¿æ³›æ”¯æŒï¼‰
                use_tls = True
        elif domain in SMTP_CONFIGS:
            # ä½¿ç”¨é¢„è®¾é…ç½®
            config = SMTP_CONFIGS[domain]
            smtp_server = config["server"]
            smtp_port = config["port"]
            use_tls = config["encryption"] == "TLS"
        else:
            print(f"æœªè¯†åˆ«çš„é‚®ç®±æœåŠ¡å•†: {domain}ï¼Œä½¿ç”¨é€šç”¨ SMTP é…ç½®")
            smtp_server = f"smtp.{domain}"
            smtp_port = 587
            use_tls = True

        msg = MIMEMultipart("alternative")

        # ä¸¥æ ¼æŒ‰ç…§ RFC æ ‡å‡†è®¾ç½® From header
        sender_name = "TrendRadar"
        msg["From"] = formataddr((sender_name, from_email))

        # è®¾ç½®æ”¶ä»¶äºº
        recipients = [addr.strip() for addr in to_email.split(",")]
        if len(recipients) == 1:
            msg["To"] = recipients[0]
        else:
            msg["To"] = ", ".join(recipients)

        # è®¾ç½®é‚®ä»¶ä¸»é¢˜
        now = get_beijing_time()
        subject = f"TrendRadar çƒ­ç‚¹åˆ†ææŠ¥å‘Š - {report_type} - {now.strftime('%mæœˆ%dæ—¥ %H:%M')}"
        msg["Subject"] = Header(subject, "utf-8")

        # è®¾ç½®å…¶ä»–æ ‡å‡† header
        msg["MIME-Version"] = "1.0"
        msg["Date"] = formatdate(localtime=True)
        msg["Message-ID"] = make_msgid()

        # æ·»åŠ çº¯æ–‡æœ¬éƒ¨åˆ†ï¼ˆä½œä¸ºå¤‡é€‰ï¼‰
        text_content = f"""
TrendRadar çƒ­ç‚¹åˆ†ææŠ¥å‘Š
========================
æŠ¥å‘Šç±»å‹ï¼š{report_type}
ç”Ÿæˆæ—¶é—´ï¼š{now.strftime("%Y-%m-%d %H:%M:%S")}

è¯·ä½¿ç”¨æ”¯æŒHTMLçš„é‚®ä»¶å®¢æˆ·ç«¯æŸ¥çœ‹å®Œæ•´æŠ¥å‘Šå†…å®¹ã€‚
        """
        text_part = MIMEText(text_content, "plain", "utf-8")
        msg.attach(text_part)

        html_part = MIMEText(html_content, "html", "utf-8")
        msg.attach(html_part)

        print(f"æ­£åœ¨å‘é€é‚®ä»¶åˆ° {to_email}...")
        print(f"SMTP æœåŠ¡å™¨: {smtp_server}:{smtp_port}")
        print(f"å‘ä»¶äºº: {from_email}")

        try:
            if use_tls:
                # TLS æ¨¡å¼
                server = smtplib.SMTP(smtp_server, smtp_port, timeout=30)
                server.set_debuglevel(0)  # è®¾ä¸º1å¯ä»¥æŸ¥çœ‹è¯¦ç»†è°ƒè¯•ä¿¡æ¯
                server.ehlo()
                server.starttls()
                server.ehlo()
            else:
                # SSL æ¨¡å¼
                server = smtplib.SMTP_SSL(smtp_server, smtp_port, timeout=30)
                server.set_debuglevel(0)
                server.ehlo()

            # ç™»å½•
            server.login(from_email, password)

            # å‘é€é‚®ä»¶
            server.send_message(msg)
            server.quit()

            print(f"é‚®ä»¶å‘é€æˆåŠŸ [{report_type}] -> {to_email}")
            return True

        except smtplib.SMTPServerDisconnected:
            print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼šæœåŠ¡å™¨æ„å¤–æ–­å¼€è¿æ¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ–ç¨åé‡è¯•")
            return False

    except smtplib.SMTPAuthenticationError as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼šè®¤è¯é”™è¯¯ï¼Œè¯·æ£€æŸ¥é‚®ç®±å’Œå¯†ç /æˆæƒç ")
        print(f"è¯¦ç»†é”™è¯¯: {str(e)}")
        return False
    except smtplib.SMTPRecipientsRefused as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼šæ”¶ä»¶äººåœ°å€è¢«æ‹’ç» {e}")
        return False
    except smtplib.SMTPSenderRefused as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼šå‘ä»¶äººåœ°å€è¢«æ‹’ç» {e}")
        return False
    except smtplib.SMTPDataError as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼šé‚®ä»¶æ•°æ®é”™è¯¯ {e}")
        return False
    except smtplib.SMTPConnectError as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ï¼šæ— æ³•è¿æ¥åˆ° SMTP æœåŠ¡å™¨ {smtp_server}:{smtp_port}")
        print(f"è¯¦ç»†é”™è¯¯: {str(e)}")
        return False
    except Exception as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥ [{report_type}]ï¼š{e}")
        import traceback

        traceback.print_exc()
        return False


def send_to_ntfy(
    server_url: str,
    topic: str,
    token: Optional[str],
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
) -> bool:
    """å‘é€åˆ°ntfyï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼Œä¸¥æ ¼éµå®ˆ4KBé™åˆ¶ï¼‰"""
    # é¿å… HTTP header ç¼–ç é—®é¢˜
    report_type_en_map = {
        "å½“æ—¥æ±‡æ€»": "Daily Summary",
        "å½“å‰æ¦œå•æ±‡æ€»": "Current Ranking",
        "å¢é‡æ›´æ–°": "Incremental Update",
        "å®æ—¶å¢é‡": "Realtime Incremental",
        "å®æ—¶å½“å‰æ¦œå•": "Realtime Current Ranking",
    }
    report_type_en = report_type_en_map.get(report_type, "News Report")

    headers = {
        "Content-Type": "text/plain; charset=utf-8",
        "Markdown": "yes",
        "Title": report_type_en,
        "Priority": "default",
        "Tags": "news",
    }

    if token:
        headers["Authorization"] = f"Bearer {token}"

    # æ„å»ºå®Œæ•´URLï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
    base_url = server_url.rstrip("/")
    if not base_url.startswith(("http://", "https://")):
        base_url = f"https://{base_url}"
    url = f"{base_url}/{topic}"

    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # è·å–åˆ†æ‰¹å†…å®¹ï¼Œä½¿ç”¨ntfyä¸“ç”¨çš„4KBé™åˆ¶
    batches = split_content_into_batches(
        report_data, "ntfy", update_info, max_bytes=3800, mode=mode
    )

    total_batches = len(batches)
    print(f"ntfyæ¶ˆæ¯åˆ†ä¸º {total_batches} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # åè½¬æ‰¹æ¬¡é¡ºåºï¼Œä½¿å¾—åœ¨ntfyå®¢æˆ·ç«¯æ˜¾ç¤ºæ—¶é¡ºåºæ­£ç¡®
    # ntfyæ˜¾ç¤ºæœ€æ–°æ¶ˆæ¯åœ¨ä¸Šé¢ï¼Œæ‰€ä»¥æˆ‘ä»¬ä»æœ€åä¸€æ‰¹å¼€å§‹æ¨é€
    reversed_batches = list(reversed(batches))

    print(f"ntfyå°†æŒ‰åå‘é¡ºåºæ¨é€ï¼ˆæœ€åæ‰¹æ¬¡å…ˆæ¨é€ï¼‰ï¼Œç¡®ä¿å®¢æˆ·ç«¯æ˜¾ç¤ºé¡ºåºæ­£ç¡®")

    # é€æ‰¹å‘é€ï¼ˆåå‘é¡ºåºï¼‰
    success_count = 0
    for idx, batch_content in enumerate(reversed_batches, 1):
        # è®¡ç®—æ­£ç¡®çš„æ‰¹æ¬¡ç¼–å·ï¼ˆç”¨æˆ·è§†è§’çš„ç¼–å·ï¼‰
        actual_batch_num = total_batches - idx + 1

        batch_size = len(batch_content.encode("utf-8"))
        print(
            f"å‘é€ntfyç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡ï¼ˆæ¨é€é¡ºåº: {idx}/{total_batches}ï¼‰ï¼Œå¤§å°ï¼š{batch_size} å­—èŠ‚ [{report_type}]"
        )

        # æ£€æŸ¥æ¶ˆæ¯å¤§å°ï¼Œç¡®ä¿ä¸è¶…è¿‡4KB
        if batch_size > 4096:
            print(
                f"è­¦å‘Šï¼šntfyç¬¬ {actual_batch_num} æ‰¹æ¬¡æ¶ˆæ¯è¿‡å¤§ï¼ˆ{batch_size} å­—èŠ‚ï¼‰ï¼Œå¯èƒ½è¢«æ‹’ç»"
            )

        # æ·»åŠ æ‰¹æ¬¡æ ‡è¯†ï¼ˆä½¿ç”¨æ­£ç¡®çš„æ‰¹æ¬¡ç¼–å·ï¼‰
        current_headers = headers.copy()
        if total_batches > 1:
            batch_header = f"**[ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡]**\n\n"
            batch_content = batch_header + batch_content
            current_headers["Title"] = (
                f"{report_type_en} ({actual_batch_num}/{total_batches})"
            )

        try:
            response = requests.post(
                url,
                headers=current_headers,
                data=batch_content.encode("utf-8"),
                proxies=proxies,
                timeout=30,
            )

            if response.status_code == 200:
                print(
                    f"ntfyç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]"
                )
                success_count += 1
                if idx < total_batches:
                    # å…¬å…±æœåŠ¡å™¨å»ºè®® 2-3 ç§’ï¼Œè‡ªæ‰˜ç®¡å¯ä»¥æ›´çŸ­
                    interval = 2 if "ntfy.sh" in server_url else 1
                    time.sleep(interval)
            elif response.status_code == 429:
                print(
                    f"ntfyç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡é€Ÿç‡é™åˆ¶ [{report_type}]ï¼Œç­‰å¾…åé‡è¯•"
                )
                time.sleep(10)  # ç­‰å¾…10ç§’åé‡è¯•
                # é‡è¯•ä¸€æ¬¡
                retry_response = requests.post(
                    url,
                    headers=current_headers,
                    data=batch_content.encode("utf-8"),
                    proxies=proxies,
                    timeout=30,
                )
                if retry_response.status_code == 200:
                    print(
                        f"ntfyç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡é‡è¯•æˆåŠŸ [{report_type}]"
                    )
                    success_count += 1
                else:
                    print(
                        f"ntfyç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡é‡è¯•å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{retry_response.status_code}"
                    )
            elif response.status_code == 413:
                print(
                    f"ntfyç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡æ¶ˆæ¯è¿‡å¤§è¢«æ‹’ç» [{report_type}]ï¼Œæ¶ˆæ¯å¤§å°ï¼š{batch_size} å­—èŠ‚"
                )
            else:
                print(
                    f"ntfyç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                try:
                    print(f"é”™è¯¯è¯¦æƒ…ï¼š{response.text}")
                except:
                    pass

        except requests.exceptions.ConnectTimeout:
            print(
                f"ntfyç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¿æ¥è¶…æ—¶ [{report_type}]"
            )
        except requests.exceptions.ReadTimeout:
            print(
                f"ntfyç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¯»å–è¶…æ—¶ [{report_type}]"
            )
        except requests.exceptions.ConnectionError as e:
            print(
                f"ntfyç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¿æ¥é”™è¯¯ [{report_type}]ï¼š{e}"
            )
        except Exception as e:
            print(
                f"ntfyç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€å¼‚å¸¸ [{report_type}]ï¼š{e}"
            )

    # åˆ¤æ–­æ•´ä½“å‘é€æ˜¯å¦æˆåŠŸ
    if success_count == total_batches:
        print(f"ntfyæ‰€æœ‰ {total_batches} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
        return True
    elif success_count > 0:
        print(f"ntfyéƒ¨åˆ†å‘é€æˆåŠŸï¼š{success_count}/{total_batches} æ‰¹æ¬¡ [{report_type}]")
        return True  # éƒ¨åˆ†æˆåŠŸä¹Ÿè§†ä¸ºæˆåŠŸ
    else:
        print(f"ntfyå‘é€å®Œå…¨å¤±è´¥ [{report_type}]")
        return False


def send_to_bark(
    bark_url: str,
    report_data: Dict,
    report_type: str,
    update_info: Optional[Dict] = None,
    proxy_url: Optional[str] = None,
    mode: str = "daily",
) -> bool:
    """å‘é€åˆ°Barkï¼ˆæ”¯æŒåˆ†æ‰¹å‘é€ï¼Œä½¿ç”¨çº¯æ–‡æœ¬æ ¼å¼ï¼‰"""
    proxies = None
    if proxy_url:
        proxies = {"http": proxy_url, "https": proxy_url}

    # è·å–åˆ†æ‰¹å†…å®¹ï¼ˆBark é™åˆ¶ä¸º 3600 å­—èŠ‚ä»¥é¿å… 413 é”™è¯¯ï¼‰
    batches = split_content_into_batches(
        report_data,
        "wework",
        update_info,
        max_bytes=CONFIG["BARK_BATCH_SIZE"],
        mode=mode,
    )

    total_batches = len(batches)
    print(f"Barkæ¶ˆæ¯åˆ†ä¸º {total_batches} æ‰¹æ¬¡å‘é€ [{report_type}]")

    # åè½¬æ‰¹æ¬¡é¡ºåºï¼Œä½¿å¾—åœ¨Barkå®¢æˆ·ç«¯æ˜¾ç¤ºæ—¶é¡ºåºæ­£ç¡®
    # Barkæ˜¾ç¤ºæœ€æ–°æ¶ˆæ¯åœ¨ä¸Šé¢ï¼Œæ‰€ä»¥æˆ‘ä»¬ä»æœ€åä¸€æ‰¹å¼€å§‹æ¨é€
    reversed_batches = list(reversed(batches))

    print(f"Barkå°†æŒ‰åå‘é¡ºåºæ¨é€ï¼ˆæœ€åæ‰¹æ¬¡å…ˆæ¨é€ï¼‰ï¼Œç¡®ä¿å®¢æˆ·ç«¯æ˜¾ç¤ºé¡ºåºæ­£ç¡®")

    # é€æ‰¹å‘é€ï¼ˆåå‘é¡ºåºï¼‰
    success_count = 0
    for idx, batch_content in enumerate(reversed_batches, 1):
        # è®¡ç®—æ­£ç¡®çš„æ‰¹æ¬¡ç¼–å·ï¼ˆç”¨æˆ·è§†è§’çš„ç¼–å·ï¼‰
        actual_batch_num = total_batches - idx + 1

        # æ·»åŠ æ‰¹æ¬¡æ ‡è¯†ï¼ˆä½¿ç”¨æ­£ç¡®çš„æ‰¹æ¬¡ç¼–å·ï¼‰
        if total_batches > 1:
            batch_header = f"[ç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡]\n\n"
            batch_content = batch_header + batch_content

        # æ¸…ç† markdown è¯­æ³•ï¼ˆBark ä¸æ”¯æŒ markdownï¼‰
        plain_content = strip_markdown(batch_content)

        batch_size = len(plain_content.encode("utf-8"))
        print(
            f"å‘é€Barkç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡ï¼ˆæ¨é€é¡ºåº: {idx}/{total_batches}ï¼‰ï¼Œå¤§å°ï¼š{batch_size} å­—èŠ‚ [{report_type}]"
        )

        # æ£€æŸ¥æ¶ˆæ¯å¤§å°ï¼ˆBarkä½¿ç”¨APNsï¼Œé™åˆ¶4KBï¼‰
        if batch_size > 4096:
            print(
                f"è­¦å‘Šï¼šBarkç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡æ¶ˆæ¯è¿‡å¤§ï¼ˆ{batch_size} å­—èŠ‚ï¼‰ï¼Œå¯èƒ½è¢«æ‹’ç»"
            )

        # æ„å»ºJSON payload
        payload = {
            "title": report_type,
            "body": plain_content,
            "sound": "default",
            "group": "TrendRadar",
        }

        try:
            response = requests.post(
                bark_url,
                json=payload,
                proxies=proxies,
                timeout=30,
            )

            if response.status_code == 200:
                result = response.json()
                if result.get("code") == 200:
                    print(
                        f"Barkç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€æˆåŠŸ [{report_type}]"
                    )
                    success_count += 1
                    # æ‰¹æ¬¡é—´é—´éš”
                    if idx < total_batches:
                        time.sleep(CONFIG["BATCH_SEND_INTERVAL"])
                else:
                    print(
                        f"Barkç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼Œé”™è¯¯ï¼š{result.get('message', 'æœªçŸ¥é”™è¯¯')}"
                    )
            else:
                print(
                    f"Barkç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€å¤±è´¥ [{report_type}]ï¼ŒçŠ¶æ€ç ï¼š{response.status_code}"
                )
                try:
                    print(f"é”™è¯¯è¯¦æƒ…ï¼š{response.text}")
                except:
                    pass

        except requests.exceptions.ConnectTimeout:
            print(
                f"Barkç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¿æ¥è¶…æ—¶ [{report_type}]"
            )
        except requests.exceptions.ReadTimeout:
            print(
                f"Barkç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¯»å–è¶…æ—¶ [{report_type}]"
            )
        except requests.exceptions.ConnectionError as e:
            print(
                f"Barkç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡è¿æ¥é”™è¯¯ [{report_type}]ï¼š{e}"
            )
        except Exception as e:
            print(
                f"Barkç¬¬ {actual_batch_num}/{total_batches} æ‰¹æ¬¡å‘é€å¼‚å¸¸ [{report_type}]ï¼š{e}"
            )

    # åˆ¤æ–­æ•´ä½“å‘é€æ˜¯å¦æˆåŠŸ
    if success_count == total_batches:
        print(f"Barkæ‰€æœ‰ {total_batches} æ‰¹æ¬¡å‘é€å®Œæˆ [{report_type}]")
        return True
    elif success_count > 0:
        print(f"Barkéƒ¨åˆ†å‘é€æˆåŠŸï¼š{success_count}/{total_batches} æ‰¹æ¬¡ [{report_type}]")
        return True  # éƒ¨åˆ†æˆåŠŸä¹Ÿè§†ä¸ºæˆåŠŸ
    else:
        print(f"Barkå‘é€å®Œå…¨å¤±è´¥ [{report_type}]")
        return False
